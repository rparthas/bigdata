{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEFmR5J_COHU"
   },
   "source": [
    "## Import Required Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEZXHo2YVq2B"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YosGM4uOCOHZ"
   },
   "outputs": [],
   "source": [
    "## change it to the unzip path of the downloaded dataset..\n",
    "os.chdir('/Users/rajagopalps/git/data/hackathons/MovieScriptsParticipantsData/')\n",
    "data_folder = 'Scripts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5MGrGh94COHh",
    "outputId": "6f3c2d5e-d458-4909-afcd-1f66475bab18"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total Number of Files : 2827\n"
    }
   ],
   "source": [
    "all_files = os.listdir(data_folder)\n",
    "print('Total Number of Files :', len(all_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3a0Y3Q0Vq2L"
   },
   "source": [
    "# Read Train Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nps340zYVq2M",
    "outputId": "2a0d42cd-f6b2-4884-b2b7-3547c4d18a1a"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          File_Name  Labels\n0     file_2180.txt       8\n1      file_693.txt       4\n2     file_2469.txt       6\n3     file_2542.txt       6\n4      file_378.txt      16\n...             ...     ...\n1973  file_1930.txt      19\n1974  file_1821.txt      19\n1975   file_350.txt      16\n1976  file_1933.txt      19\n1977  file_1210.txt      11\n\n[1978 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File_Name</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file_2180.txt</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file_693.txt</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file_2469.txt</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file_2542.txt</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file_378.txt</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1973</th>\n      <td>file_1930.txt</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1974</th>\n      <td>file_1821.txt</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1975</th>\n      <td>file_350.txt</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>1976</th>\n      <td>file_1933.txt</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1977</th>\n      <td>file_1210.txt</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n<p>1978 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "train_df = pd.read_csv('Train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZIUam5eVVq2Q",
    "outputId": "ddd148da-7dfc-4e25-bca7-e39bf1c506b6"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6     405\n19    261\n4     243\n0     203\n5     141\n15    134\n1     116\n16    109\n11    104\n8      79\n14     75\n7      27\n2      25\n20     18\n13     15\n21      9\n12      4\n9       3\n3       2\n17      2\n10      2\n18      1\nName: Labels, dtype: int64"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "train_df.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYZ9t9U8Vq2W",
    "outputId": "92198597-c824-4597-9a5b-c74df7552130"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         File_Name\n0    file_2300.txt\n1     file_809.txt\n2    file_1383.txt\n3     file_983.txt\n4    file_1713.txt\n..             ...\n844  file_2474.txt\n845   file_863.txt\n846  file_1547.txt\n847  file_1292.txt\n848  file_1910.txt\n\n[849 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File_Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>file_2300.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>file_809.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>file_1383.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>file_983.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>file_1713.txt</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>844</th>\n      <td>file_2474.txt</td>\n    </tr>\n    <tr>\n      <th>845</th>\n      <td>file_863.txt</td>\n    </tr>\n    <tr>\n      <th>846</th>\n      <td>file_1547.txt</td>\n    </tr>\n    <tr>\n      <th>847</th>\n      <td>file_1292.txt</td>\n    </tr>\n    <tr>\n      <th>848</th>\n      <td>file_1910.txt</td>\n    </tr>\n  </tbody>\n</table>\n<p>849 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "test_df = pd.read_csv('Test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3x3bITvVq2Y",
    "outputId": "c24ee160-1caa-4a07-db6c-6c0b3c3d9fe3"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "file_1532.txt    1\nfile_499.txt     1\nfile_985.txt     1\nfile_2263.txt    1\nfile_1095.txt    1\n                ..\nfile_1672.txt    1\nfile_530.txt     1\nfile_528.txt     1\nfile_1586.txt    1\nfile_971.txt     1\nName: File_Name, Length: 849, dtype: int64"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "test_df.File_Name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UL0RRzLVq2b",
    "outputId": "50d43098-7937-4531-9296-9f8b20ba1b42"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "22 849\n"
    }
   ],
   "source": [
    "print(train_df.Labels.nunique(), test_df.File_Name.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0DqMPYhrVq2d"
   },
   "outputs": [],
   "source": [
    "## let's read the text scripts in the train and test dataframes..\n",
    "\n",
    "train_df['Script'] = [open(data_folder + os.sep + file, \"r\").read() for file in train_df['File_Name']]\n",
    "test_df['Script'] = [open(data_folder + os.sep + file, \"r\").read() for file in test_df['File_Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WU5cBRg5Vq2f"
   },
   "source": [
    "# Lets look at a script file after Reading.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uC2QnjwzVq2g",
    "outputId": "6a6fc548-1566-40e0-97f4-b79bb5344bf8",
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<b><!--\n\n</b>if (window!= top)\n\ntop.location.href=location.href\n\n<b>// -->\n\n</b>\n\nThe Abyss - by James Cameron \n\n                                  THE ABYSS\n\n                            AN ORIGINAL SCREENPLAY\n\n                                      BY\n\n                                JAMES CAMERON\n\n                               August 2, 1988\n\n                             Director's Revision\n\n------------------------------------------------------------------------------\n\n                                  THE ABYSS\n\nOMITTED                                                                 1\n\nOMITTED                                                                 2\n\nTITLE: THE ABYSS -- ON BLACK, DISSOLVING TO COBALT BLUE\n\nEXT. OCEAN/UNDERWATER -- DAY                                            3\n\nBlue, deep and featureless, the twilight of five hundred feet down.\n\nPROPELLER SOUND.  Materializing out of the blue limbo is the enormous but\n\nsleek form of an Ohio-class SSBN ballistic missile submarine.\n\nINT. U.S.S. MONTANA -- DAY                                              4\n\nIn the attack center, darkened to womb-red, the crew's faces shine with sweat\n\nin the glow of their instruments.  The SKIPPER and his EXEC crowd around\n\nBARNES, the sonarman.\n\n                                CAPTAIN\n\n                Sixty knots?  No way, Barnes... the reds don't\n\n                have anything that fast.\n\n                                BARNES\n\n                Checked it twice, skipper.  It's a real unique\n\n                signature.  No cavitation, no reactor noise...\n\n                doesn't even sound like screws.\n\nHe puts the signal onto a speaker and everyone in the attack room listens to\n\nthe intruder's acoustic signature, a strange THRUMMING.  The captain studies\n\nthe electronic position board, a graphic representation of the contours of\n\nthe steep-walled canyon, a symbol for the Montana, and converging with it, an\n\namorphous trace, representing the bogey.\n\n                                CAPTAIN\n\n                What the hell is it?\n\n                                EXEC\n\n                I'll tell you what it's not, it's not one of\n\n                ours.\n\n                                BARNES\n\n                Sir!  Contact changing heading to two-one-four,\n\n                diving.  Speed eighty knots!  Eighty knots!\n\n                                EXEC\n\n                Eighty knots...\n\n                                BARNES\n\n                Still diving, depth nine hundred feet.  Port\n\n                clearance to cliff wall, one hundred fifty feet.\n\n                                FRANK\n\n                           (simultaneously)\n\n                Still diving, depth nine hundred feet.  Port\n\n                clearance to cliff wall, one hundred fifty feet.\n\nTension builds in the attack room as the Montana surges to intercept the\n\nintruder.  The exec tensely watches the vector-graphic readout for the side-\n\nscan sonar array.  The sub is running uncomfortably\n"
    }
   ],
   "source": [
    "#lets check one of the scripts..\n",
    "print(train_df['Script'][4][:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vvQ6vOcVq2j",
    "outputId": "a3d04d6a-c61d-43ea-cb48-ac18a07ae219"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "KING KONG\n\n                                          Written by\n\n                        Fran Walsh, Philippa Boyens and Peter Jackson\n\n                                     Based on a Story by\n\n                             Merian C. Cooper and Edgar Wallace\n\n                                                                   1.\n\n          EXT. CENTRAL PARK - DAY\n\n          CLOSE ON: A scrawny MONKEY scratches.\n\n          ANGLES ON: Defeated, listless ANIMALS, in the bleak environs of a\n\n          dilapidated ZOO.\n\n          WIDER: It is CENTRAL PARK ZOO in depression era NEW YORK. The PARK\n\n          itself is like a GARBAGE DUMP, dotted with squalid SHANTY TOWNS.\n\n          Against these BLEAK IMAGES, the SOUND of a BRIGHT, BRASSY SONG\n\n          fades up: Al Jolson, singing \"I'm Sitting on Top of the World\".\n\n          The sky line of MANHATTAN rises in the background, a grim steaming\n\n          jungle on this cold FALL day.\n\n                                                        I\n\n          EXT. NY STREETS - DAY\n\n          LONG continues over:\n\n          IMAGES: The CROWDED STREETS of NEW YORK ... beneath the bustle is\n\n          a sense of despair.\n\n          LONG SOUP LINES snake along the STREETS.\n\n          The HUNGRY search through RUBBISH BINS for FOOD. SKYSCRAPERS rise\n\n          steadily upwards as more people are evicted from their homes.\n\n          HOMELESS sleep amid steaming VENTS and GARBAGE STREWN GUTTERS.\n\n                                                             Intercut:\n\n          INT. VAUDEVILLE THEATRE - NIGHT\n\n          SONG continues over:\n\n          I\n\n          SANNY, an old-time VAUDEVILLIAN, hurriedly fixes a large DROOPY\n\n          MOUSTACHE on to a YOUNG WOMAN'S TOP LIP ... this is ANN DARROW.\n\n          IMAGES: Weird and wonderful snatches of VAUDEVILLE ACTS follow ...\n\n          singers, jugglers, boxing ladies.\n\n          E\n\n                                                        Intercut with:\n\n          EXT. NY STREETS - DAY\n\n          The COLOR and MUSIC contrast with the SOUP LINES and SLUMPED\n\n          SHOULDERS of the REAL WORLD.\n\n          INT. VAUDEVILLE THEATRE - NIGHT\n\n          ANGLE ON: ANN on STAGE ... dressed as an ELEGANT GENT, she\n\n          launches into `I'm Just Wild About Harry' with HARRY, a larger-\n\n          than-life PERFORMER dressed in a FRILLY DRESS, BRASSY RED WIG and\n\n          FALSIES.\n\n                                                                   2.\n\n          MANNY's CHARACTER joins in ... SNEEZING LOUDLY and causing ANN to\n\n          take a SUDDEN PRAT FALL.\n\n           nd so the ROUTINE BUILDS ... ANN and HARRY singing and dancing\n\n          ... MANNY SNEEZING ... ANN falling.\n\n          The AUDIENCE look on with bored expressions on their faces. All\n\n          except ONE MAN at the BACK, who is LAUGHING HYSTERICALLY.\n\n          CLOSE ON: ANN throwing everything into her ACT ... SWEAT rolls\n\n          down her face ... she tries\n"
    }
   ],
   "source": [
    "print(test_df['Script'][4][:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "5Z6GyVjFD9aH",
    "outputId": "309eb172-19cc-40a4-e198-bc24dbf4d804"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6     405\n19    261\n4     243\n0     203\n5     141\n15    134\n1     116\n16    109\n11    104\n8      79\n14     75\n7      27\n2      25\n20     18\n13     15\n21      9\n12      4\n9       3\n3       2\n17      2\n10      2\n18      1\nName: Labels, dtype: int64"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "train_df.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LdCtl00oCOIZ"
   },
   "outputs": [],
   "source": [
    "# !pip install keras\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxPpQJw0Vq2q"
   },
   "source": [
    "### There is single instance for one class (Label == 18), lets duplicate the row for stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lplIhy8NVq2r"
   },
   "outputs": [],
   "source": [
    "train_df = train_df.append(train_df[train_df['Labels'] == 18])\n",
    "train_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rkZO1-p1Vq2t",
    "outputId": "91becbaf-df92-4200-ca21-59d66bb44981"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6     405\n19    261\n4     243\n0     203\n5     141\n15    134\n1     116\n16    109\n11    104\n8      79\n14     75\n7      27\n2      25\n20     18\n13     15\n21      9\n12      4\n9       3\n3       2\n17      2\n18      2\n10      2\nName: Labels, dtype: int64"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "train_df.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ZzXe4SqVq2x"
   },
   "source": [
    "# Import the Modeling Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_cell_guid": "d46ba3fd-26f1-4635-b2f9-fca916ff3066",
    "_uuid": "21f3ccd962d1556dc2346699d45a29e9ef791367",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XvGfW6yECOIb",
    "outputId": "3f818c87-cc25-4cf7-cd09-2a530b458b7a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "60326be1-82d1-4677-8ef8-da5b1eac475c",
    "_uuid": "adb496504ab8453ce2b4f91dd6e5f17cbdaf4f68",
    "colab_type": "text",
    "id": "erL7TVmYCOId"
   },
   "source": [
    "Let's load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "f-2g2ajRCOIe",
    "outputId": "06d8c71f-741e-4c9d-9d2b-ab90cfb07a2e",
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/rajagopalps/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ARKw1PXBVq25"
   },
   "source": [
    "# Define the Scoring Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_agx-HVVq25"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4a37951-7a53-43b9-bb5a-0335f1259be3",
    "_uuid": "14ede2221105fb84bb6b2d3a85f9a1f483e8b124",
    "colab_type": "text",
    "id": "a81kkCgECOIq"
   },
   "source": [
    "### Let's Use LabelEncoder from scikit-learn to convert Genre labels to integers, 0, 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "_cell_guid": "d59a646d-7739-496c-814f-594d371d76eb",
    "_uuid": "19eb8c10f06df8e0f543ee12f794df5f88b0ff1a",
    "colab": {},
    "colab_type": "code",
    "id": "avnO-wf9COIq"
   },
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(train_df.Labels.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "65403e74-091f-43c4-9523-3e15d8a75a1e",
    "_uuid": "4ffd04f40d9e921673d06ad64e01b9a7395d8e76",
    "colab_type": "text",
    "id": "8OtK6PLsCOIs"
   },
   "source": [
    "### Before going further it is important that we split the data into training and validation sets. We can do it using \n",
    "#### `train_test_split` from the `model_selection` module of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_cell_guid": "ba8e606d-8dee-495e-8c3f-62aa916e9927",
    "_uuid": "b45676b121e2b719d355619e24cfed13d0d33f74",
    "colab": {},
    "colab_type": "code",
    "id": "tqXblO-mCOIt"
   },
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train_df.Script.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_cell_guid": "9e2fe6a9-8de0-4bbd-8264-f6b78e7993e2",
    "_uuid": "6c8659049537836fdf00d19d6d656630a306d217",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ce_Eu4CrCOIu",
    "outputId": "042067e3-a5ad-4f5a-c727-0581878fdd86"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1385,)\n(594,)\n"
    }
   ],
   "source": [
    "print (xtrain.shape)\n",
    "print (xvalid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3db70c26-d684-478a-bcd4-980ed6c6d65b",
    "_uuid": "794fb768f4a8e42c4be4f1dbb27144aae4d00c79",
    "colab_type": "text",
    "id": "unBlwkZ1COIx"
   },
   "source": [
    "# Building Basic Models\n",
    "\n",
    "### Let's start building our very first model. \n",
    "\n",
    "### Our very first model is a simple TF-IDF (Term Frequency - Inverse Document Frequency) followed by a simple Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_cell_guid": "b387f2af-11b1-455d-ad8d-320ed1005be3",
    "_uuid": "350d453dc982f494c3774dbdcf731d856546d611",
    "colab": {},
    "colab_type": "code",
    "id": "qnJ8aPthCOIx"
   },
   "outputs": [],
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7DA_QK7aVq3I"
   },
   "source": [
    "## TFIDF on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzSPvE6pVq3J"
   },
   "outputs": [],
   "source": [
    "x_test_tfv = tfv.transform(test_df['Script'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_cell_guid": "4106bbd1-dc35-4dc2-bda0-3024d3c056d3",
    "_uuid": "3f5dd9ce043364fc61ba3a30298acd9cb72a2938",
    "colab": {},
    "colab_type": "code",
    "id": "NhMszJiuCOIz"
   },
   "outputs": [],
   "source": [
    "## Fitting a simple Logistic Regression on TFIDF\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print(\"logloss: %0.3f \" % log_loss(yvalid, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OsW7SEHUVq3M"
   },
   "source": [
    "# Submission "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qgN8HVaUVq3N"
   },
   "source": [
    "### Let's predict on the entire test data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6RV2jDiVq3N"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-da89835b111f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_set_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_set_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'File_Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile_Name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_set_preds = pd.DataFrame(columns = train_df.Labels.unique().tolist())\n",
    "test_set_preds.insert(0, 'File_Name', test_df.File_Name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gOI9x-0Vq3P"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-255a25b8129c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_set_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_tfv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "test_set_preds[test_df.Labels.unique().tolist()] = clf.predict_proba(x_test_tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2wHkWIyVq3S",
    "outputId": "52af681f-882d-4f13-abf2-8e03041daf13"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_set_preds' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d91266b0dd82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_set_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_set_preds' is not defined"
     ]
    }
   ],
   "source": [
    "test_set_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wRIKKTeWVq3W",
    "outputId": "18d12eb3-26b4-473b-e3ab-b930d1b3c945"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_set_preds' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7b7b17c14a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_set_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_set_preds' is not defined"
     ]
    }
   ],
   "source": [
    "test_set_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEeQA9VGVq3a"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-5-fce95a2772d5>, line 2)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-fce95a2772d5>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    test_set_preds = test_set_preds[['File_name',0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\u001b[0m\n\u001b[0m                                                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#Reorder the columns to match the Sample_submission_file\n",
    "test_set_preds = test_set_preds[['File_name',0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "052WdJ-ZVq3Y"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'test_set_preds' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c24e20890de9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Write your submissions to an excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_set_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_set_preds_v1.0.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_set_preds' is not defined"
     ]
    }
   ],
   "source": [
    "#Write your submissions to an excel file\n",
    "test_set_preds.to_excel('test_set_preds_v1.0.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Follow the sample submission format for your submission file\n",
    "\n",
    "#### Please verify the following before submitting your solution to avoid an invalid sibmission.\n",
    "\n",
    "1. The format of the file is excel(.xlsx)\n",
    "\n",
    "2. The file doesn’t contain additional styling elements such as bold headings or table borders\n",
    "\n",
    "3. The length of the submission exactly matches with that of the sample submission and test set\n",
    "\n",
    "4. The file name doesnot have any spaces or special characters\n",
    "\n",
    "5. All the columns are present"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Starter_Notebook_For_Participants.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda6f005690c5a24f80b204c8f05f403d84"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}